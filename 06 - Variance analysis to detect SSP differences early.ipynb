{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate two factorial ANOVA \n",
    "\n",
    "In order to detect masks with early emerging signals we can run varaiance analysis ANOVA. This will tell us if there are differences between SSPs, but will not serve to differantiate new observations. The goal is to detect which masks allows for an early seperation between SSPs, this allows for easier development of ML algs.\n",
    "\n",
    "Here we run two factorial design hereunder\n",
    "- Mask as factor, with global levels of nomask, seamask and landmask\n",
    "- SSP as factor, with levels SSP126, SSP245, SSP370 and SSP585¨\n",
    "Since all levels of each factor occours in combination we have 12 groups and a crossed model design (in difference to a nested model design). \n",
    "\n",
    "We run the factors as descriptive variables for observations of tas, pr, txx and rx5day. Since the interaction between these responsvariables is what will allow us to detect SSP seperation early we use multivariate analysis of variance or MANOVA. \n",
    "\n",
    "Since we use a yearly cross-sectional approach for classification we run two-factorial MANOVA on each cross section.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of data and initial investigation\n",
    "In order to enable the analysis we need to transform our data from seperate multivariate time series files on the .nc format, to a table for each seperate cross section (year). The format will be:\n",
    "\n",
    "| # | Mask | SSP | tas_value | pr_value | txx_value | rx5day_value |\n",
    "| --|---|---|---|---|---|---|\n",
    "....\n",
    "\n",
    "This allows to run the analysis directly if each realization gets one row each. While performing this preprocessing some initial investigations will be performed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigations of time series ensambles.\n",
    "It is always important to know the big picture of what you are looking at. Therefor we start by presenting the ensambles of each variable under different masks. In order to calculate the ensambles we use the xclim library. \n",
    "\n",
    "**Sources:**\n",
    "- https://xclim.readthedocs.io/en/stable/index.html\n",
    "    - https://xclim.readthedocs.io/en/stable/notebooks/ensembles.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'msc_env (Python 3.12.1)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.preproces import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from xclim import ensembles\n",
    "\n",
    "file_handler = Handle_Files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'msc_env (Python 3.12.1)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def legend_without_duplicate_labels(fig):\n",
    "    handles, labels = fig.axes[0].get_legend_handles_labels()\n",
    "    unique = [(h, l) for i, (h, l) in enumerate(zip(handles, labels)) if l not in labels[:i]]\n",
    "    fig.legend(*zip(*unique), loc='center left', bbox_to_anchor=(1, 0.5), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'msc_env (Python 3.12.1)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "fig, axs = plt.subplots(4, 3, figsize=(15, 12), sharey='row')#, sharex='col')\n",
    "fig2, axs2 = plt.subplots(4, 3, figsize=(15, 12), sharey='row')#, sharex='col')\n",
    "\n",
    "main_data_dir = '/nird/home/johannef/Masterthesis_S23 DataFiles/AnnualGlobalClimatologies'\n",
    "masks = ['nomask', 'landmasked', 'seamasked']\n",
    "SSPs = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "variables = ['tas', 'pr', 'rx5dayETCCDI', 'txxETCCDI']\n",
    "\n",
    "colors = plt.cm.coolwarm(np.linspace(0, 1, len(SSPs)))\n",
    "color_map = dict(zip(SSPs, colors))\n",
    "\n",
    "for i, mask in enumerate(masks):\n",
    "    \n",
    "    for j, variable in enumerate(variables):\n",
    "        axs[j, i].set_ylabel(variable)\n",
    "        axs[j, i].set_title(f'{variable} ({mask})')\n",
    "        axs2[j, i].set_ylabel(variable)\n",
    "        axs2[j, i].set_title(f'{variable} ({mask})')\n",
    "\n",
    "        means = {}\n",
    "        stds = {}\n",
    "        for scenario in SSPs:\n",
    "            data_dir = '/'.join([main_data_dir, mask, variable, scenario])\n",
    "\n",
    "            ens = ensembles.create_ensemble(Path(data_dir).glob(\"*.nc\"))\n",
    "            ens_stats = ensembles.ensemble_mean_std_max_min(ens)\n",
    "            \n",
    "            ens_mean = ens_stats[f'{variable}_mean']\n",
    "            ens_std = ens_stats[f'{variable}_stdev']\n",
    "            axs[j, i].plot(ens_stats.year, ens_mean, \n",
    "                           label=scenario,\n",
    "                           color=color_map[scenario])\n",
    "            axs[j, i].fill_between(ens_stats.year, ens_mean - ens_std, ens_mean + ens_std, \n",
    "                                   color=color_map[scenario],\n",
    "                                   alpha=0.5)\n",
    "\n",
    "            means[scenario] = ens_mean\n",
    "            stds[scenario] = ens_std\n",
    "        \n",
    "        mean = np.mean(means.values())\n",
    "\n",
    "        for scenario in means.keys(): \n",
    "            # meanscaled version\n",
    "            # Kan ikke skalere med gruppegjennomsnittet må benytte gjennomsnittet av alle sspene\n",
    "            meanscaled_ens_mean = means[scenario] - mean\n",
    "            meanscaled_ens_std = stds[scenario] - mean\n",
    "            axs2[j, i].fill_between(ens_stats.year, meanscaled_ens_mean - meanscaled_ens_std, meanscaled_ens_mean + meanscaled_ens_std, \n",
    "                                   color=color_map[scenario],\n",
    "                                   alpha=0.5)\n",
    "            axs2[j, i].plot(ens_stats.year, meanscaled_ens_mean, \n",
    "                            label=scenario,\n",
    "                            color=color_map[scenario])\n",
    "            \n",
    "\n",
    "legend_without_duplicate_labels(fig)\n",
    "legend_without_duplicate_labels(fig2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datawrangling for table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'msc_env (Python 3.12.1)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def extract_cross_sections(data_dir, ssp_names, center_year, target_mapping, pm=1):\n",
    "    \n",
    "    start_year = center_year - pm\n",
    "    end_year = center_year + pm  \n",
    "\n",
    "    df = pd.DataFrame(columns=['pr', 'tas', 'target_ssp'], \n",
    "                      index=np.arange(len(ssp_names)*40))\n",
    "    indx = 0\n",
    "\n",
    "    for ssp_name in ssp_names:\n",
    "        ssp_dir = os.path.join(data_dir, ssp_name)\n",
    "        file_list = os.listdir(ssp_dir)\n",
    "\n",
    "        for file_name in file_list:\n",
    "            file_path = os.path.join(ssp_dir, file_name)\n",
    "            ds = xr.open_dataset(file_path)\n",
    "            \n",
    "            ds_years = ds.sel(year=slice(start_year, end_year))\n",
    "            mean_pr = ds_years.pr.mean(dim='year').values\n",
    "            mean_tas = ds_years.tas.mean(dim='year').values\n",
    "\n",
    "            df.loc[indx] = [mean_pr, mean_tas, target_mapping[ssp_name]] \n",
    "            \n",
    "            indx += 1         \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots \n",
    "one for every fift years?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MANOVA adequacy checking\n",
    "s. 167\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MANOVA testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc Linear disciminant analysis (LDA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
